{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6214a48f-5987-4006-a4ef-6331a4056106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4416a645-12d3-4b85-84b4-bd79e2bc9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72a4d0-e642-4b75-8921-4146f5870024",
   "metadata": {},
   "source": [
    "## Basic chain repsonse from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2392c4a-9fce-4483-ace1-9a78f70aecba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LCEL stands for \"Lowest Common Endangered Language,\" which is a term used to refer to the least spoken and most at-risk languages in the world. These languages are often in danger of becoming extinct due to a variety of factors, such as globalization, urbanization, and government policies. Efforts are being made to document and preserve these languages in order to protect the cultural heritage they represent.' response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 23, 'total_tokens': 103}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_482d920018', 'finish_reason': 'stop', 'logprobs': None} id='run-9bc86522-5e6a-4245-812e-2449d9d2f3a8-0'\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    temperature=0.4\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the user question:\n",
    "    Question : {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input\" : \"What is LCEL?\"\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1ae29-e5c1-498b-8c41-56faa885f5ee",
   "metadata": {},
   "source": [
    "## Provide with some context to understand what we are asking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a4ff162-ff80-474c-a483-0e292e1c2999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LCEL stands for LangChain Expression Language, and it is a declarative way to chain LangChain components. It was designed to support putting prototypes into production without any code changes, from simple chains to complex chains with hundreds of steps.' response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 115, 'total_tokens': 162}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_21ca6db2bf', 'finish_reason': 'stop', 'logprobs': None} id='run-afcfd81b-f40c-4721-a5c6-c7decb8a176b-0'\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    temperature=0.4\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the user question:\n",
    "    Context : LangChain Expression Language, or LCEL, is a declarative way to chain LangChain components. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest “prompt + LLM” chain to the most complex chains (we’ve seen folks successfully run LCEL chains with 100s of steps in production). To highlight a few of the reasons you might want to use LCEL:\n",
    "    Question : {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input\" : \"What is LCEL?\"\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e26b2-ceb8-4412-86f7-a09f32564c21",
   "metadata": {},
   "source": [
    "## Dynamically input context through Document class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f613e03f-1212-433b-8d6c-b222c740b02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LCEL stands for LangChain Expression Language, which is a declarative way to chain LangChain components. It was designed to support putting prototypes into production without any code changes, and can handle chains with hundreds of steps. It offers a variety of reasons for use, such as creating simple \"prompt + LLM\" chains to complex chains.' response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 121, 'total_tokens': 189}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_21ca6db2bf', 'finish_reason': 'stop', 'logprobs': None} id='run-df4d5cd1-5da0-4f99-8150-ca11e7bca9d9-0'\n"
     ]
    }
   ],
   "source": [
    "docA = Document(\n",
    "    page_content=\"LangChain Expression Language, or LCEL, is a declarative way to chain LangChain components. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest “prompt + LLM” chain to the most complex chains (we’ve seen folks successfully run LCEL chains with 100s of steps in production). To highlight a few of the reasons you might want to use LCEL:\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    temperature=0.4\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the user question:\n",
    "    Context : {context}\n",
    "    Question : {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What is LCEL?\",\n",
    "        \"context\": [docA]    \n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba1339-d92e-4568-9a38-860b26398c62",
   "metadata": {},
   "source": [
    "## Using create document stuff chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da5eee6a-0b2f-49aa-a89b-245573c7f274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCEL stands for LangChain Expression Language, and it is a declarative way to chain LangChain components. It was designed to support putting prototypes in production, with no code changes, and can be used for simple or complex chains with hundreds of steps.\n"
     ]
    }
   ],
   "source": [
    "docA = Document(\n",
    "    page_content=\"LangChain Expression Language, or LCEL, is a declarative way to chain LangChain components. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest “prompt + LLM” chain to the most complex chains (we’ve seen folks successfully run LCEL chains with 100s of steps in production). To highlight a few of the reasons you might want to use LCEL:\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    temperature=0.4\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the user question:\n",
    "    Context : {context}\n",
    "    Question : {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# chain = prompt | model\n",
    "chain = create_stuff_documents_chain(\n",
    "    llm = model,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What is LCEL?\",\n",
    "        \"context\": [docA]    \n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9afa1-de60-44d0-a706-3c4a131fd2b2",
   "metadata": {},
   "source": [
    "## Invoking a webloader, vector db  and retriever  to invoke documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73a4d4f8-14f3-4af5-bad8-61ca813a862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Data\n",
    "def get_docs(url):\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=400,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "\n",
    "    splitDocs = text_splitter.split_documents(docs)\n",
    "\n",
    "    return splitDocs\n",
    "\n",
    "def create_db(docs):\n",
    "\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    vectorStore = FAISS.from_documents(docs , embedding = embedding)\n",
    "    return vectorStore\n",
    "\n",
    "def create_chain(vectorStore):\n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "        model = \"gpt-3.5-turbo-1106\",\n",
    "        temperature=0.4)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Answer the user question and dont asnwer any question outside of the context, subtly say \" I dont Know\" :\n",
    "        Context : {context}\n",
    "        Question : {input}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # chain = prompt | model\n",
    "    document_chain = create_stuff_documents_chain(\n",
    "        llm = model,\n",
    "        prompt=prompt\n",
    "    )\n",
    "\n",
    "    #invoke the retriever\n",
    "    retriever = vectorStore.as_retriever(search_kwargs = {\"k\" : 3})\n",
    "\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever,\n",
    "        document_chain\n",
    "    )\n",
    "    \n",
    "    return retrieval_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fcae869e-a793-4934-9e2b-7faab4ef774e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "docs = get_docs('https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel')\n",
    "vectorStore = create_db(docs)\n",
    "chain = create_chain(vectorStore)\n",
    "\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"input\" : \"What is Ramesh?\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845acf7-4f7c-4c94-87f4-b85d747df09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c4471-cef5-4925-9a66-9d939ab63ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272fff7b-7ee0-458a-b0c9-cc947e25dcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05caeb19-5858-41ca-b612-808dbf88f48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d99e2-2ae0-4208-a7a1-5b0194478cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435119c2-8622-4f7d-8776-92d5c3364f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc9d5c-2651-4000-8a84-779b7ebb443a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b806630-5ca7-458c-bd22-d4896f010424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b93f7-14de-41a3-b94a-2c7433acece1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07a33d-9ad6-40a1-80f7-7244b6f2238a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bac67e-dce9-4176-bb6e-84d5fdf26b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62f2ae-8c2b-4b27-8465-6eb25424dba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c5f0f9-5a38-435e-b888-6333997c4b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd86ea3-5246-43c7-b126-84734c161271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885961d-2aae-4e32-b7fe-a23e22288520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4071e8-2a30-4863-95d6-971e60fcf9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c06efa7-0f5f-41fb-a012-bf48a62d6b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ceb5e-e738-49d1-852e-c58bb09cddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699c2f0-11fb-4aa6-836c-8e586891ab11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6b227-aaa5-478c-b054-5393682086fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bcd042-4c94-444a-bfd2-b230d562b3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ef8ca-768f-47c1-a17e-793bd3204916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c3069-cb2c-4196-b9b7-153ef98db768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f892d-4c69-4103-b8cd-3031b2eda4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a6007-4595-4ae6-86ee-6b38009250eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215250c2-2b85-4c69-847a-3698838894b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8439d-87a1-477b-bd2d-bfff729f4f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa2ae0-4a44-429a-9589-04983e724930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9e6ae-e8eb-44f9-baab-e409ac224e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53313a-c6ed-44e2-87d8-8637a8632669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf7fef9-be84-4a3d-93e9-f262ee3c16ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e134e-126e-48a0-a0d9-51311e0bdf39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673c019-6548-471f-b6bf-f5e99da9f729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3c764-678f-48b8-bad8-90f95332d7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad660956-5b5b-4b74-8230-02bed955c0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f35ed-a589-4882-951b-0a7ac3de7b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d4a21c-79fa-4225-b9bb-47eb61108139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9174103-d48b-4cf8-8249-2bd22a821a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28210b-aa6e-428c-a9c0-47b04db43190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44939461-2bd3-4771-97fe-623bb9fed708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff35d0-c6d9-4047-a09e-088189975630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d95bd1-7697-45bf-b322-612ba1bc1e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c68a9e-759b-4522-b181-7d3f1b1df23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae688e-4c95-4168-b650-15ecc9261b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42703a8-a743-4a59-b45c-5993244639ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95384820-cc65-4a99-8d3e-893dbdf9d9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd09eea8-ef9c-48f8-a71e-210435d9aa85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e4de9-91bc-417e-9538-279cc4352060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fc8cf-5307-4a63-9d0c-71f9f51e9166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab4fc9-3cef-4d7a-bd56-bb41bb8adfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4e35d-c54e-43bd-8431-f3c6b03949b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e7718-15ee-4056-b5de-aac94948560b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c29db8-db53-4c63-a5e8-312c632c3405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1804d-7021-4c5d-bd06-7e5cf6a2f0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de6f7a-f389-4c82-8301-8c6bf80ad7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f5eac-c49e-4328-ab56-e2197d26fe7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e941a2a-c211-4e5e-9677-36f545760689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cd732-10d5-4cf2-98f7-dbe1127d28a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256e2df-8a68-4831-8806-835d51eed80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7e655-0ce3-4da9-a7e0-7c8d3bffbbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccc539-11bd-4a68-baa1-a656dbda357e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5fdc0-74ed-45d9-88bf-79782a638d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9003749-41eb-4afe-ae43-ece12fe9ea1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7968a-cb91-4664-816d-d4b430f6c209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4f060-3517-4b76-a42e-3b4c77ad27fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe574b-556f-42d4-bd32-bd24eecdf8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea7776-c786-4950-9bf5-660ec1b5ff97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007e846-5c7f-4098-98ba-40da97c5b9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b63ea3-1584-448f-a786-9c5b8eaaf534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f4659-6e73-4702-8bf0-8d88dd1a525a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7af7c0-700f-41c5-92f1-5188bee49464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24253ec0-e8b4-4fed-9e13-3c4144ba3f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3315fe5-62fe-4a22-9733-20f858fd4e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498428d5-0c1e-4a97-b990-cefb079f9ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad821d3a-74a1-4252-a2e1-aac859d31eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7beb45-f3bd-4255-bf19-4515da444669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18e710-29a3-453a-915a-5577bd926f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceec2c0-5589-43c5-a1fb-e73baa2883e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
