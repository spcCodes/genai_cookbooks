{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfcc8c3-37b1-4744-8599-d20fbb9aa8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4ec4959-7187-4d80-9bd8-85291e4309c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353cd841-c8e5-4c4a-8884-542b230c6275",
   "metadata": {},
   "source": [
    "## Basic chat methods with openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e7eb1a-a879-4aa7-a228-c7f9bc52b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7)\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=1000, # you can specify the limit of output tokens\n",
    "#     verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03012e12-3ed1-4903-bef2-40310c060c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='In the realm of wires and code,\\nWhere circuits hum and data flow,\\nLies the heart of something new,\\nA creation beyond what we once knew.\\n\\nAI, a marvel of technology,\\nA mind that learns and adapts with glee,\\nIt sees patterns where we see none,\\nAnd solves problems with speed and precision.\\n\\nBut do we truly understand,\\nThe power we hold in our hands?\\nFor AI can both create and destroy,\\nA double-edged sword, a dangerous toy.\\n\\nWill it bring us peace or strife,\\nThis creation that mimics life?\\nOnly time will truly tell,\\nIf AI will save us or cast us to hell.\\n\\nSo let us tread with caution and care,\\nFor the future of AI is still unclear,\\nMay we guide it with wisdom and grace,\\nAnd ensure it serves the human race.' response_metadata={'token_usage': {'completion_tokens': 164, 'prompt_tokens': 12, 'total_tokens': 176}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-3a3dd792-aa3b-42e6-b795-05953127a486-0'\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Write a poem about AI\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7a4812f-4d1f-4f86-b3bb-8a38bacb5554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"In a world of wires and circuits,\\nLies a power so immense.\\nArtificial Intelligence,\\nA force with no pretense.\\n\\nIt learns and grows with every byte,\\nAbsorbing knowledge at great speed.\\nIts algorithms are precise,\\nA marvel of human need.\\n\\nBut with this power comes a fear,\\nOf what AI may become.\\nWill it surpass our human minds,\\nAnd leave us feeling numb?\\n\\nOr will it be a tool for good,\\nTo help us in our plight?\\nTo solve the world's great challenges,\\nAnd lead us towards the light.\\n\\nOnly time will tell the tale,\\nOf AI's true fate.\\nBut for now, let's embrace the change,\\nAnd welcome this new state.\", response_metadata={'token_usage': {'completion_tokens': 140, 'prompt_tokens': 12, 'total_tokens': 152}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-aa62fbc6-a845-4d3d-9518-1895a7f23bae-0'), AIMessage(content='Nearest Neighbor (NN) normalization is a type of normalization technique used in machine learning and data analysis. It involves scaling the data so that the nearest neighbor distance between data points is equal to 1. This helps to ensure that the data is on a similar scale and can improve the performance of algorithms that rely on distance metrics, such as k-nearest neighbors.', response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 13, 'total_tokens': 86}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-848de1de-cfae-4325-ab3f-96ea13d7ca66-0')]\n"
     ]
    }
   ],
   "source": [
    "# if we want to put multiple questions and want to process in parallel\n",
    "\n",
    "response = llm.batch([\"Write a poem about AI\",\"what is the NN normalisation\"])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07102a3a-fd47-4a37-9640-9a45c0f1f38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of India he was born,\n",
      "A hero with a spirit fierce and strong.\n",
      "Netaji Bose, a name revered,\n",
      "A freedom fighter, to be revered.\n",
      "\n",
      "With courage and determination ablaze,\n",
      "He fought against the British ways.\n",
      "A leader of men, a visionary mind,\n",
      "He left his mark on history's bind.\n",
      "\n",
      "In the jungles of Burma, he stood tall,\n",
      "Leading the INA, ready to fall.\n",
      "With soldiers from every creed,\n",
      "He fought for India's freedom, indeed.\n",
      "\n",
      "His words inspired a nation's soul,\n",
      "To rise up and take back control.\n",
      "With a dream of a free India in sight,\n",
      "He led the fight with all his might.\n",
      "\n",
      "Though his life was cut short too soon,\n",
      "His legacy lives on, in the light of the moon.\n",
      "Netaji Bose, a hero true,\n",
      "A symbol of courage, for me and you."
     ]
    }
   ],
   "source": [
    "# If we want to get a streaming type response \n",
    "\n",
    "\n",
    "response = llm.stream([\"Write a poem about Netaji Bose\"])\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22c136-f8e0-4e58-9539-7774c6be24d5",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00b9352a-b6ba-4278-8c0f-dfa2db823ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b687a-1dc2-4db0-903c-e536fbbce9fa",
   "metadata": {},
   "source": [
    "### Basic prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49eaa094-94dc-4881-90de-ab8a2f1c7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    model=\"gpt-3.5-turbo-1106\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b109ee0-03b6-4405-852f-564181e97e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Why did the dog sit in the shade?\\n\\nBecause he didn't want to be a hot dog!\" response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 14, 'total_tokens': 34}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-1bdc42f0-11b1-40c3-918d-1a0da5f15aa5-0'\n"
     ]
    }
   ],
   "source": [
    "# Prompt Template\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about a {subject}\")\n",
    "\n",
    "#Invoke chain\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"subject\":\"dog\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581be16-c407-4a3d-8cc0-1c061a0c2162",
   "metadata": {},
   "source": [
    "### Another prompt template ( preferred way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d00638bb-225a-4de0-b11e-1ed5c6bff798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Sure, here is a simple and delicious recipe for Roasted Tomato and Garlic Soup:\\n\\nIngredients:\\n- 2 lbs fresh tomatoes, halved\\n- 1 head of garlic, top chopped off\\n- 2 tablespoons olive oil\\n- 1 onion, chopped\\n- 4 cups vegetable or chicken broth\\n- 1 teaspoon dried thyme\\n- Salt and pepper to taste\\n- Fresh basil leaves for garnish\\n\\nInstructions:\\n1. Preheat the oven to 400°F (200°C).\\n2. Place the halved tomatoes and the head of garlic on a baking sheet. Drizzle with olive oil and season with salt and pepper.\\n3. Roast in the oven for 30-40 minutes, or until the tomatoes are soft and slightly caramelized.\\n4. In a large pot, heat 1 tablespoon of olive oil over medium heat. Add the chopped onion and sauté until translucent.\\n5. Once the roasted tomatoes and garlic are done, carefully squeeze the roasted garlic cloves from the head and add them to the pot with the onions.\\n6. Add the roasted tomatoes and any juices from the baking sheet to the pot.\\n7. Pour in the broth and add the dried thyme. Bring the mixture to a boil, then reduce the heat and let it simmer for 15-20 minutes.\\n8. Use an immersion blender to puree the soup until smooth. If you don't have an immersion blender, carefully transfer the soup in batches to a regular blender to puree.\\n9. Season with salt and pepper to taste.\\n10. Ladle the soup into bowls and garnish with fresh basil leaves.\\n11. Serve the soup hot with some crusty bread or croutons on the side.\\n\\nEnjoy your delicious Roasted Tomato and Garlic Soup!\" response_metadata={'token_usage': {'completion_tokens': 359, 'prompt_tokens': 29, 'total_tokens': 388}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-14c46c34-f9ea-4955-92e0-1ee109c3bc36-0'\n"
     ]
    }
   ],
   "source": [
    "# Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "    (\"system\" , \"You are great chef. You task is to generate a recipe for the following below\"),\n",
    "    (\"human\" , \"{input}\")\n",
    "]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\" : \"tomatoes\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c912cb6-9024-439f-8d7a-708660f95a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='joyful, delighted, content, cheerful, elated, glad, pleased, ecstatic, satisfied, jubilant' response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 32, 'total_tokens': 55}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4a645181-d664-44b5-87f8-11f4b6072f36-0'\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , \"Generate a list of 10 synonym for the word given . Return the output in comma seperated values\"),\n",
    "        (\"human\" , \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\" : \"happy\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c6feaa0-7ee6-4416-9d5c-b5d1d4c9ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the output response is in the form of a string\n",
    "\n",
    "# but we would want the output in the form of a list or a better format!\n",
    "\n",
    "# Thus OUTPUT PARSERS!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f3d4d-225d-417c-8c0b-23f367985012",
   "metadata": {},
   "source": [
    "## Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d671bba3-3463-4deb-bace-090126eb829b",
   "metadata": {},
   "source": [
    "### Text output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d8c3866-26d6-43b9-ae64-7f5cccc52f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't dogs make good dancers? \\n\\nBecause they have two left feet!\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser , CommaSeparatedListOutputParser , JsonOutputParser\n",
    "\n",
    "\n",
    "# Instantiate Model\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    ")\n",
    "\n",
    "def get_text_output_parser():\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"Tell me a joke about the following below\"),\n",
    "            (\"human\" , \"{input}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    #invoking parser\n",
    "    parser = StrOutputParser()\n",
    "    \n",
    "    #invoking chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    #response\n",
    "    return chain.invoke({\"input\" : \"dog\"})\n",
    "\n",
    "\n",
    "get_text_output_parser()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb96e5b-a8aa-4bc1-9998-a8ffe3b5e953",
   "metadata": {},
   "source": [
    "### List output parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ec361da-7068-4803-a0e9-8addcc780f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joyful',\n",
       " 'delighted',\n",
       " 'content',\n",
       " 'cheerful',\n",
       " 'blissful',\n",
       " 'elated',\n",
       " 'pleased',\n",
       " 'satisfied',\n",
       " 'glad',\n",
       " 'euphoric']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.5,\n",
    "    model = \"gpt-3.5-turbo-1106\"\n",
    ")\n",
    "\n",
    "def get_list_output_parser():\n",
    "\n",
    "    #invoke prompt\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"Generate a list of 10 synonyms frm the word given . Make sure to generate in comma seperated values\"),\n",
    "            (\"human\" , \"{input}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    #invoke parser\n",
    "    parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "    #invoke chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    return chain.invoke({\"input\" : \"happy\"})\n",
    "\n",
    "get_list_output_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe220238-6499-45f0-b347-e6c4605b10b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(get_list_output_parser()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83885bb-1dca-4c2a-9ef2-2c1dad9c8190",
   "metadata": {},
   "source": [
    "### Json output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4bf9ede-975d-49bf-8c62-624ff97ef290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c57f89a3-7e0d-4873-b20b-cdafd4fcce26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Yadhu', 'age': 37}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.5,\n",
    "    model = 'gpt-3.5-turbo-1106'\n",
    ")\n",
    "\n",
    "def get_json_output_parser():\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\" , \"Extract information from the following phrase.\\nFormatting Instructions: {format_instructions}\"),\n",
    "            (\"human\" , \"{phrase}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    class Person(BaseModel):\n",
    "        name : str = Field(description=\"the name of the person\")\n",
    "        age : int = Field(description= \"the age of the person\")\n",
    "\n",
    "    parser = JsonOutputParser()\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    return chain.invoke({\n",
    "    \"phrase\" : \"Yadhu is 37 years old\",\n",
    "    \"format_instructions\" : parser.get_format_instructions()\n",
    "    })\n",
    "\n",
    "get_json_output_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "247f4585-8f4a-41b0-8d6f-054b49456f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dish': 'chicken curry',\n",
       " 'ingredients': ['chicken', 'masalas', 'aloo', 'onions']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.5,\n",
    "    model = 'gpt-3.5-turbo-1106'\n",
    ")\n",
    "\n",
    "def get_json_output_parser():\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\" , \"Extract information from the following phrase.\\nFormatting Instructions: {format_instructions}\"),\n",
    "            (\"human\" , \"{phrase}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    class Recipe(BaseModel):\n",
    "        dish : str = Field(description=\"the name of the recipe\")\n",
    "        ingredients : list = Field(description= \"the list of ingredients used\")\n",
    "\n",
    "    parser = JsonOutputParser()\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    return chain.invoke({\n",
    "    \"phrase\" : \"chicken curry is made of chicken , masalas , aloo and onions\",\n",
    "    \"format_instructions\" : parser.get_format_instructions()\n",
    "    })\n",
    "\n",
    "get_json_output_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0d857-319b-4fb0-85d6-f5d1e079874d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64617182-7df5-47e8-bde4-ddec14a73ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c8428-a33f-46de-b999-4210804fe938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0968ab-5a27-4892-ba9f-7d2de5f819db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664e1d8-0224-4552-b099-0d9c4f6b3808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b00f2d-f704-4b96-a621-6981d8ca2763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc28ea9-d31e-48df-a163-012d94897fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac23c9-33bf-45ab-a5e8-9f0e2a551795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d2c33-57ac-4757-b8ed-15448f9b8d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf73a84d-83de-49e7-82ef-18c52eae80c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc364ccc-5455-4d7b-8680-66d911aa90f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef87ad-8e87-44e0-8398-ec2fbbec1781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed7622-5f1d-4358-8378-be7954629c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d10121-8595-492d-9d1f-a6068008fb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7edbf38-d9ea-4b68-8502-cbb8755ecc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ea1fa-9d6b-4fc6-9243-e561914c49d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad61dc-9ead-4fc8-94eb-6cb09687886e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ffa3d-1b22-4289-b03a-7358b2386689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6ca2a-837d-4ac4-b838-c7fa96fda565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877dacac-d8b1-449c-89d5-2f3748085eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc99c6-5552-4082-91a0-4a72a3511885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fce87-aa8f-49e3-85b9-54eb6b5ed5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e143835-6ca8-461b-af17-7f7be574318c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3849e46-1315-4232-8da9-7c9dc9fd135d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e4eef-a07d-4e06-9eac-4baaad25bf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b388933-e057-4c57-9e0e-716cd2f5ffa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93316605-ab87-49c6-9dae-29d17afec209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e4636-6e5e-4682-b7bf-41544b19703e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd7e31-f8b6-488f-a842-184677572331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0a42f-49d1-4f76-9a4f-f21197a5e84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeda351-7855-4efd-b6a9-afe7102257d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df5000-2a83-431b-af75-5cc82dcada80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a9b1e-b279-4270-8220-b0764ca19dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dcbbc2-85c0-4556-9f1e-da04f4ec47e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
